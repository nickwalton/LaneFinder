{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing some useful packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import scipy.misc as scipyimg\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lane Finder Using Canny Edge Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Takes the name of an image as input and saves the augmented image in the test_images_output folder\n",
    "def process_image(image):\n",
    "    #Convert to grayscale\n",
    "    gray = cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    #Do gaussian smoothing\n",
    "    kernel_size = 3\n",
    "    blur_gray = cv2.GaussianBlur(gray,(kernel_size,kernel_size),0)\n",
    "\n",
    "    #Run Canny edge detection\n",
    "    low_threshold = 50\n",
    "    high_threshold = 100\n",
    "    edges = cv2.Canny(blur_gray, low_threshold, high_threshold)\n",
    "\n",
    "    # Define Region of Interest and mask edges outside of it\n",
    "    mask = np.zeros_like(edges)   \n",
    "    ignore_mask_color = 255   \n",
    "\n",
    "    # Define region using a 4 sided polygon\n",
    "    imshape = image.shape\n",
    "    vertices = np.array([[(250,imshape[0]-60),(480, 460), (imshape[1]-440, 460), (imshape[1]-150,imshape[0]-60)]], dtype=np.int32)\n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    masked_edges = cv2.bitwise_and(edges, mask)\n",
    "\n",
    "    #plt.imshow(masked_edges)\n",
    "\n",
    "\n",
    "    #Define Hough Transform Parameters\n",
    "    rho = 1 # distance resolution in pixels of Hough grid\n",
    "    theta = np.pi/180 # angular resolution in radians of grid\n",
    "    threshold = 20 #miminum number of votes or intersections in hough grid\n",
    "    min_line_length = 30 #minimum number of pixels making up a line\n",
    "    max_line_gap = 5 #maximum gap in pixels between line segments\n",
    "    line_image = np.zeros_like(image)\n",
    "\n",
    "    #Run hough transform\n",
    "    lines = cv2.HoughLinesP(masked_edges,\n",
    "                            rho, theta, threshold, np.array([]), min_line_length, max_line_gap)\n",
    "\n",
    "    #Collection of x and y points in left lane and right lane\n",
    "    left_lane = [[],[]]\n",
    "    right_lane = [[],[]]\n",
    "\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            if(((y2-y1)/(x2-x1) > 0.5) and (x2 > 480 and x1 > 480)):\n",
    "                right_lane[0].extend([x1,x2])\n",
    "                right_lane[1].extend([y1,y2])\n",
    "                cv2.line(line_image,(x1,y1),(x2,y2),(0,0,255),6)\n",
    "            elif (((y2-y1)/(x2-x1) < -0.5) and (x2 < 480 and x1 < 480)):\n",
    "                left_lane[0].extend([x1,x2])\n",
    "                left_lane[1].extend([y1,y2])\n",
    "                cv2.line(line_image,(x1,y1),(x2,y2),(0,0,255),6)\n",
    "\n",
    "    #If points for left lane are found, extrapolate lane and draw onto image\n",
    "    if(len(left_lane[0]) != 0):\n",
    "        left_line = np.polyfit(left_lane[0],left_lane[1],1)\n",
    "        y1 = imshape[1]\n",
    "        x1 = int((y1-left_line[1])/left_line[0])\n",
    "        y2 = 440 #height we want the projected lines to go to\n",
    "        x2 = int((y2-left_line[1])/left_line[0])\n",
    "        cv2.line(line_image, (x1, y1), (x2, y2), [255,0,0], 8)\n",
    "        #cv2.line(line_image, (250,imshape[0]-100), (450, 460), [255,0,0], 8)\n",
    "    \n",
    "    #If points for right lane are found, extrapolate lane and draw onto image\n",
    "    if(len(right_lane[0])!= 0):\n",
    "        right_line = np.polyfit(right_lane[0],right_lane[1],1)\n",
    "        y1 = imshape[1]\n",
    "        x1 = int((y1-right_line[1])/right_line[0])\n",
    "        y2 = 440 #height we want the projected lines to go to\n",
    "        x2 = int((y2-right_line[1])/right_line[0])\n",
    "        cv2.line(line_image, (x1, y1), (x2, y2), [255,0,0], 8)\n",
    "        #cv2.line(line_image, (imshape[1]-400, 460), (imshape[1]-150,imshape[0]-100), [255,0,0], 8)\n",
    "\n",
    "    #create a color binary image to combine with the line image\n",
    "    #color_edges = np.dstack((edges, edges, edges))\n",
    "\n",
    "    #Draw the lines on the edge image\n",
    "    augmented_lanes = cv2.addWeighted(image, 0.8, line_image, 1, 0)\n",
    "\n",
    "    #scipyimg.imsave(\"test_images_output/\" + image_name, augmented_lanes)\n",
    "    return augmented_lanes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "#reading in an image\n",
    "images = os.listdir(\"test_images/\")\n",
    "for image_name in images:\n",
    "    image = mpimg.imread(\"test_images/\" + image_name)\n",
    "    augment_lanes(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Processing Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video test_videos_output/challenge.mp4\n",
      "[MoviePy] Writing video test_videos_output/challenge.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [00:30<00:00,  5.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_videos_output/challenge.mp4 \n",
      "\n",
      "CPU times: user 1min 11s, sys: 1.25 s, total: 1min 13s\n",
      "Wall time: 33.3 s\n"
     ]
    }
   ],
   "source": [
    "challenge_output = 'test_videos_output/challenge.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "##clip3 = VideoFileClip('test_videos/challenge.mp4').subclip(0,5)\n",
    "clip3 = VideoFileClip('test_videos/challenge.mp4')\n",
    "challenge_clip = clip3.fl_image(process_image)\n",
    "%time challenge_clip.write_videofile(challenge_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
